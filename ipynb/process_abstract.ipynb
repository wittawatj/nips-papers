{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to get abstracts of all papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#config InlineBackend.figure_format = 'pdf'\n",
    "from IPython.core.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "try:\n",
    "    import cPickle as pickle \n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "import scipy.sparse as sp\n",
    "import string\n",
    "import sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get abstracts from the raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paper_dataframe(fpath):\n",
    "    rows = []\n",
    "    with open(fpath, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        # Each read gives ['Id', 'Title', 'EventType', 'PdfName', 'Abstract', 'PaperText']\n",
    "        reader.next()\n",
    "        for row in reader:\n",
    "            rows.append(tuple(row))\n",
    "    data = pd.DataFrame(rows, columns=['Id', 'Title', 'EventType', \n",
    "                                   'PdfName', 'Abstract', 'PaperText'])\n",
    "    return data\n",
    "\n",
    "def get_abstract_from_paper_text(text):\n",
    "    \"\"\"\n",
    "    Attempt to extract out the abstract of a paper from a raw text content\n",
    "    taken out from the pdf. The content should look something like:\n",
    "    \n",
    "    ASSOCIATIVE LEARNING\n",
    "    VIA INHIBITORY SEARCH\n",
    "    David H. Ackley\n",
    "    Bell Communications Research\n",
    "    Cognitive Science Research Group\n",
    "\n",
    "    ABSTRACT\n",
    "    ALVIS is a reinforcement-based connectionist architecture that\n",
    "    learns associative maps in continuous multidimensional environments. The discovered locations of positive and negative reinforcements are recorded in \"do be\" and \"don't be\" subnetworks,\n",
    "    respectively. ...........\n",
    "\n",
    "    INTRODUCTION\n",
    "    The \"backpropagation algorithm\" or generalized delta rule (Rumelhart, Hinton, &\n",
    "    Williams, 1986) is sometimes cr\n",
    "    \n",
    "    The function relies on the keyword \"abstract\" in its own line as \n",
    "    the beginning of the abstract, and the fact that there\n",
    "    is one empty line after the abstract. \n",
    "    \n",
    "    return the abstract if sucess. Otherwise, return None.\n",
    "    \"\"\"\n",
    "    # locate the line in which there is only the word \"abstract\"\n",
    "    lines = text.split('\\n')\n",
    "    abs_line_start = -1\n",
    "    abs_line_end = -1\n",
    "    # linear search\n",
    "    for i, L in enumerate(lines):\n",
    "        if L.strip().lower() == 'abstract':\n",
    "            # The following line to an empty line is the abstract\n",
    "            abs_line_start = i+1\n",
    "            break\n",
    "    \n",
    "    if abs_line_start == -1:\n",
    "        return None\n",
    "    \n",
    "    for i in xrange(abs_line_start+2, len(lines)):\n",
    "        L = lines[i]\n",
    "        if L.strip() == '':\n",
    "            abs_line_end = i\n",
    "            break\n",
    "    \n",
    "    if abs_line_end == -1:\n",
    "        return None\n",
    "    \n",
    "    abstract = ' '.join(lines[abs_line_start:abs_line_end])\n",
    "    return abstract.strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dframe = paper_dataframe('Papers1988_2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 30, 90, 171\n",
    "ind = 171\n",
    "\n",
    "a_paper = dframe['PaperText'][ind]\n",
    "print a_paper[:1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print get_abstract_from_paper_text(a_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the abstract for each paper\n",
    "n_docs = dframe.shape[0]\n",
    "abstracts = []\n",
    "\n",
    "for i in xrange(n_docs):\n",
    "    paper_i = dframe['PaperText'][i]\n",
    "    abstract_i = get_abstract_from_paper_text(paper_i)\n",
    "    abstracts.append(abstract_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# papers that do not have an abstract\n",
    "print [i for (i, ab) in enumerate(abstracts) if ab is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the pickle containing the document-term matrix, \n",
    "# put the abstracts in, and dump it to a file.\n",
    "fyear = 1988\n",
    "tyear = 2015\n",
    "dt_fpath = 'DT_%d_%d.p'%(fyear, tyear)\n",
    "\n",
    "with open(dt_fpath, 'r') as f:\n",
    "    info = pickle.load(f)\n",
    "\n",
    "# include the abstracts\n",
    "info['abstracts'] = abstracts\n",
    "# save the pickle\n",
    "dt_dest = 'DT_%d_%d_wabs.p'%(fyear, tyear)\n",
    "with open(dt_dest, 'w') as f:\n",
    "    pickle.dump(info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
